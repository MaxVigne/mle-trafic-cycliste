import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from src.streamlit_utils import plotly_map, fixNaN, get_lieux_compteurs_df

@st.cache_data
def load_raw_data():
    df_2023 = pd.read_csv('data/raw/2023-comptage-velo-donnees-compteurs.csv', sep=';')
    df_2024 = pd.read_csv('data/raw/2024-comptage-velo-donnees-compteurs.csv', sep=';') 
    df = pd.concat([df_2023, df_2024], axis=0)
    df = fixNaN(df)
    return df

# Charger les donn√©es
df = pd.read_csv("data/processed/lieu-compteur-one-hot-encoded.csv", index_col=0)

st.image("streamlit_assets/banniere6.jpeg", use_container_width=True)

#Titres
st.title("**Projet Data Science - Trafic Cycliste √† Paris**")
st.subheader("_de F√©vrier √† Mars 2025_")

st.sidebar.title("Sommaire")
pages=["Pr√©sentation du Projet", "Pr√©sentation du dataset", "Pr√©processing", "Visualisation des donn√©es", "Mod√®les de classification", "Mod√®les de r√©gression", "Interpr√©tation et r√©sultats", "Conclusion"]
page=st.sidebar.radio("Aller vers", pages)


## Pr√©sentation du projet
if page == pages[0]:
    st.header("Pr√©sentation du projet", divider=True)

    st.header("I. Contexte")

    st.markdown("""
Face √† l'essor du v√©lo comme mode de transport durable, la Ville de Paris a mis en place, depuis plusieurs ann√©es, un r√©seau de compteurs √† v√©lo permanents pour mesurer l'√©volution de la pratique cycliste dans la capitale.

Ces capteurs, install√©s sur les axes cl√©s de la ville, collectent en continu des donn√©es sur le flux des cyclistes.
    """)

    st.image("streamlit_assets/comptagev√©lo.jpeg", use_container_width=True)

    st.markdown("""
Ce projet s'inscrit dans une d√©marche de transition vers une mobilit√© plus verte et une volont√© d'adapter les infrastructures urbaines aux besoins r√©els, tel que propos√© dans le plan v√©lo 2021-2026 d'am√©nagement de pistes cyclables de la mairie de Paris.

L'enjeu est de transformer ces donn√©es brutes en insights exploitables, permettant d'√©clairer les d√©cisions publiques de mani√®re objective et data-driven.
    """)

    st.divider()

    st.header("II. Objectifs")
    st.markdown("Ce projet vise √† d√©velopper un **outil pr√©dictif du trafic cycliste √† Paris**, en exploitant les donn√©es historiques des compteurs v√©lo.")

    st.subheader("Objectifs principaux")
    st.markdown("""
- Identifier les **tendances d‚Äôusage** (heures de pointe, zones satur√©es, variations saisonni√®res).
- G√©n√©rer des **visualisations claires** (cartes thermiques, graphiques temporels).
- Aider √† la **prise de d√©cision** sur les am√©nagements √† prioriser.
""")

    st.subheader("B√©n√©fices pour la Mairie de Paris :")
    st.markdown("""
- Prioriser les **am√©nagements cibl√©s** (pistes √©largies, carrefours s√©curis√©s, nouveaux itin√©raires).
- √âvaluer l‚Äô**impact des politiques existantes**.
- **Optimiser le r√©seau cyclable** √† long terme.
""")

    st.subheader("Ambition finale")
    st.markdown("> R√©duire les **conflits d‚Äôusage**, am√©liorer la **s√©curit√©**, et encourager la pratique du v√©lo gr√¢ce √† une **planification data-driven**, combinant **r√©trospective** et **pr√©diction** pour une mobilit√© plus fluide et r√©siliente.")








## Pr√©sentation du dataset
if page == pages[1]: 
    st.header("Pr√©sentation du dataset", divider=True)
    st.header("1. Sources des donn√©es")
    st.image("streamlit_assets/opendata2.png", use_container_width=True)
    st.markdown("""
Utilisation des jeux de donn√©es ouverts propos√©s par la Ville de Paris via [opendata.paris.fr](https://opendata.paris.fr) :

  - le jeu de donn√©es [Comptage v√©lo - Donn√©es compteurs](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/information) pour les donn√©es de 2024-2025.
  - le jeu de donn√©es [Comptage v√©lo - Historique - Donn√©es Compteurs et Sites de comptage](https://opendata.paris.fr/explore/dataset/comptage-velo-historique-donnees-compteurs/information) pour les donn√©es de 2023.
                 
Les donn√©es sont publi√©es sous la licence Open Database License (ODbL), qui autorise la r√©utilisation, l‚Äôadaptation et la cr√©ation de travaux d√©riv√©s √† partir de ces jeux de donn√©es, √† condition d‚Äôen citer la source.
""") 

    st.divider()

    st.header("2. P√©riode ")
    st.markdown("""
Les donn√©es sont mises √† jour quotidiennement. 

Nous avons r√©cup√©r√© toutes les donn√©es du 1er janvier 2023 au 28 f√©vrier 2025 (26 mois).                
""") 

    st.divider()

    st.header("3. Contenu des jeux de donn√©es  ")
    st.markdown("""
Les jeux de donn√©es recensent les comptages horaires des passages de v√©los effectu√©s par environ une centaine de compteurs r√©partis dans la ville de Paris.
                  
Chaque lieu de comptage est g√©n√©ralement √©quip√© de deux compteurs, face √† face, positionn√©s pour mesurer le trafic dans chaque direction d‚Äôune m√™me rue. 
                 
Au total, pour la p√©riode 2023-2024, le jeu de donn√©es contient environ 1,8 million de lignes r√©parties sur 16 variables.
""")

    st.divider()

    st.header("4. Structure des donn√©es")
    st.markdown("""
Chaque ligne du dataset correspond au nombre de v√©los enregistr√©s pendant une heure par un compteur donn√©.  

Les donn√©es incluent, en plus du comptage horaire, plusieurs m√©tadonn√©es associ√©es au compteur ou au site de comptage, telles que :
- Le nom et l‚Äôidentifiant du compteur  
- Le nom du lieu de comptage (en g√©n√©ral n¬∫ + rue)
- La date d‚Äôinstallation du compteur
- Les coordonn√©es g√©ographiques  
- √âventuellement, des liens vers des photos du site
""")

    st.divider()
    st.header("5. Nettoyage et s√©lection des variables  ")

    st.markdown("""
Afin de simplifier et d‚Äôoptimiser l‚Äôanalyse, nous avons supprim√© les variables non pertinentes pour l'entra√Ænement du mod√®le, en particulier les champs techniques ou visuels comme les liens vers les photos, les identifiants internes ou le type d‚Äôimage.  

Voici un extrait de notre dataset avec les variables que nous avons d√©cid√© de conserver :
""")

    st.dataframe(load_raw_data().sample(5))

    st.divider()

    st.header("6. Objectif d‚Äôanalyse et variable cible  ")
    st.markdown("""
L‚Äôobjectif de notre √©tude est de pr√©dire le nombre de v√©los compt√©s pendant une heure sur un compteur donn√©.  
La variable cible de notre mod√®le est donc le comptage horaire, un indicateur cl√© pour analyser l'√©volution de la circulation cycliste dans Paris.
""")

    st.divider()
    st.header("7. Forces et limites du dataset")

    st.markdown("""
Le dataset se distingue par sa pr√©cision horaire et sa couverture g√©ographique dense, ce qui permet d‚Äôidentifier des tendances temporelles comme les variations quotidiennes ou saisonni√®res du trafic cycliste.  

Cependant, il ne contient pas d‚Äôinformations contextuelles telles que :
- La m√©t√©o  
- La pr√©sence d‚Äô√©v√©nements particuliers (manifestations, gr√®ves, festivals)  
- Ou des donn√©es sociod√©mographiques comme la densit√© de population par zone  

Cette absence limite la profondeur des analyses pr√©dictives que l‚Äôon peut mener.
""")

## Pr√©processing
if page == pages[2]: 
    st.header("Pr√©processing des donn√©es", divider=True)
    st.header("1. Suppression des NaN")

    st.markdown("""
    Certaines variables de m√©tadonn√©es des compteurs ("Identifiant du compteur", "Coordonn√©es g√©ographiques", ...) ont des valeurs NaN (environ 3.4% sur le dataset)

    Plusieurs compteurs du dataset correspondaient en r√©alit√© √† un m√™me emplacement, ce qui a permis de r√©duire les NaN en les renommant et fusionnant. 

    Les derniers NaN provenaient de deux compteurs atypiques, finalement supprim√©s pour obtenir un dataset complet et sans valeurs manquantes
    """) 
        
    st.header("2. Conversion Date au format datetime") 
                    
    st.markdown("""
    Variable "Date et heure de comptage" convertie au format datetime de Pandas, en utilisant le fuseau horaire Europe/Paris afin de correctement capturer les tendances journali√®res.
    """) 
                    
    st.code("""
    # Convertir la colonne en datetime (avec gestion du fuseau horaire)
    df['Date et heure de comptage'] = pd.to_datetime(df['Date et heure de comptage'], utc=True)
    df['Date et heure de comptage'] = df['Date et heure de comptage'].dt.tz_convert("Europe/Paris")
    """, language="python")

    st.header("3. Ajout de variables")
    st.markdown("""                
    La variable "Date et heure de comptage" d√©compos√©e en variables "ann√©e", 
    "mois", "jour", "jour de la semaine" et "heure" afin de faciliter la data visualisation et voir si 
    certaines de ces variables √©taient corr√©l√©s √† notre variable cible.
    """)
    
    st.code("""
    df["Jour"] = df["Date et heure de comptage"].dt.date
    df["Mois"] = df["Date et heure de comptage"].dt.month
    df["Ann√©e"] = df["Date et heure de comptage"].dt.year
    df["Heure"] = df["Date et heure de comptage"].dt.hour
    """, language="python")

    st.markdown('Ajout des variables cat√©gorielles binaires "Week-end", "Jour f√©ri√©s" et "Vacances scolaires" afin de mesurer si les jours non travaill√©s ont un impact sur la pratique cyclable.') 

    st.header("4. Normalisation des donn√©es")

    st.markdown("""
    Nous avons appliqu√© deux types de **normalisation** sur les colonnes temporelles et contextuelles, notamment pour r√©duire l'impact des valeurs extr√™mes de Comptage horaire sur les pr√©dictions de notre mod√®le,  la variable Comptage horaire ne suivant pas une loi normale :

    1. **Standardisation** : centre les donn√©es autour de 0 avec une variance de 1.
    2. **Min-Max Scaling** : transforme les valeurs dans une plage d√©finie, ici entre 0 et 1.
    """)

    st.subheader("üîπ Standardisation")

    st.code("""
    from sklearn.preprocessing import StandardScaler

col_norm = ["Jour", "Mois", "Ann√©e", "Heure", "Jour_semaine", "Jour f√©ri√©", "Vacances scolaires"]

scaler = StandardScaler()
df[col_norm] = scaler.fit_transform(df[col_norm])
    """, language="python")

    st.subheader("üîπ Normalisation Min-Max")

    st.code("""
from sklearn.preprocessing import MinMaxScaler

col_norm = ["Jour", "Mois", "Ann√©e", "Heure", "Jour_semaine", "Jour f√©ri√©", "Vacances scolaires"]

scaler = MinMaxScaler(feature_range=(0, 1))
df[col_norm] = scaler.fit_transform(df[col_norm])
    """, language="python")

    st.markdown("""
    Ces transformations permettent de pr√©parer les donn√©es pour les mod√®les sensibles √† l‚Äô√©chelle des variables (r√©gressions, KNN, etc.).
    """)

    st.header("Extrait du Dataframe apr√®s pr√©-processing")
    st.dataframe(df.head(10))




## Visualisation des donn√©es                
if page == pages[3]: 
    raw_data = load_raw_data()

    st.header("Visualisation des donn√©es", divider=True)
    st.header("I. Cartographie")
    st.markdown("Carte de la ville de Paris repr√©sentant les positions des diff√©rents compteurs du dataset. La taille de chaque point correspond au comptage horaire total.")

    st.plotly_chart(plotly_map(load_raw_data()))

    st.markdown("""
    Les compteurs sont r√©partis sur les axes principaux :
            
    - Sud-Ouest / Nord-Est (avenue Denfert-Rochereau et boulevard S√©bastopol) 
    - Est-Ouest (avenue de la Grande Arm√©e et avenue des Champs-√âlys√©es). 
    - Les quais de la Seine ainsi que le boulevard p√©riph√©rique Sud (le long de la voie de tram T3a) sont aussi couverts. 
                
    Boulevard p√©riph√©rique nord et les 17 et 18e arrondissements n'ont pas de compteurs. 
    
    Compteurs "centraux" ont plus de comptage que ceux en p√©riph√©rie de Paris : 
    Corr√©lation entre la localisation du compteur et le comptage horaire ?""")

    st.header("II. √âvolution temporelle")

    st.subheader("""a. √âvolution globale du trafic""")
    fig = plt.figure(figsize=(12, 5))
    comptage_quotidien = raw_data.groupby("date")["Comptage horaire"].sum()
    plt.plot(comptage_quotidien.index.astype(str), comptage_quotidien.values, linestyle = "-", color = "orange")

    plt.xlabel("Jour")
    plt.ylabel("Nombre de v√©los")
    plt.title("√âvolution du comptage quotidien des v√©los")
    plt.xticks(ticks = range(0, len(comptage_quotidien), 15), labels = comptage_quotidien.index[::15].astype(str), rotation = 45, fontsize = 8)

    plt.grid(axis = "y", linestyle = "--", alpha = 0.7)
    st.pyplot(fig)

    st.markdown("""
On peut observer ici certaines tendances notamment des diminutions significatives
au mois d'Ao√ªt et D√©cembre qui correspondent respectivement √† une saison chaude
pendant les vacances scolaires (voyages, etc.) et √† No√´l (saison plus froide et familiale).
Il semble √©galement y avoir une reprise au mois de Septembre montrant la reprise du travail 
et la rentr√©e pour les √©tudiants.
""")

    st.subheader("""b. Saisonnalit√© du trafic""")
    
    fig = plt.figure()
    sns.barplot(df, x='Mois', y='Comptage horaire', errorbar=None)
    plt.xlabel("Mois")
    plt.xticks(rotation=45)
    plt.title("Comptage horaire moyen en fonction du mois")
    st.pyplot(fig)

    st.markdown("""
    On constate une baisse du comptage en **hiver** (janvier et d√©cembre) et en **√©t√©** (au mois d'ao√ªt).

    Cela est peut-√™tre d√ª aux **vacances**, √† certains **√©v√©nements** (JO de Paris en ao√ªt) et √† la **m√©t√©o** (il fait plus froid en hiver, ce qui n'encourage pas la pratique cycliste).""")

    st.subheader("""c. Comportement selon les jours""")
    
    fig = plt.figure(figsize=(10, 5))
    sns.barplot(df, x='Jour_semaine', y='Comptage horaire', errorbar=None)
    plt.xlabel("Jour du mois")
    plt.title("Comptage horaire moyen en fonction du jour de la semaine")
    st.pyplot(fig)

    st.markdown("""
    On constate √©galement plus de **comptages** du **lundi au vendredi**, ce qui correspond aux **trajets domicile-travail**.

    En moyenne, il y a environ **50% de v√©los en plus** en **semaine** par rapport au **week-end**.
    """)


    st.subheader("""d. Evolution du trafic au fil des heures""")

    st.markdown("""√Ä gauche : **jours de la semaine** (lundi √† vendredi) ‚Äî √Ä droite : **week-end** (samedi et dimanche)""")

    # Filtrage
    df_semaine = df[df['Jour_semaine'].isin([1, 2, 3, 4, 5])]
    df_weekend = df[df['Jour_semaine'].isin([6, 7])]

    # D√©termination du m√™me axe Y pour les deux graphiques
    y_max = max(df['Comptage horaire'].max(), 1)  # max global pour fixer l'√©chelle

    # Cr√©ation des deux graphiques c√¥te √† c√¥te
    fig, axes = plt.subplots(1, 2, figsize=(20, 7), sharey=True)

    # Graphique semaine
    sns.barplot(ax=axes[0], data=df_semaine, x='Heure', y='Comptage horaire', errorbar=None)
    axes[0].set_title("Comptage horaire moyen (lundi √† vendredi)")
    axes[0].set_xlabel("Heure de la journ√©e")
    axes[0].set_ylabel("Comptage horaire")
    axes[0].set_ylim(0, 400)

    # Graphique week-end
    sns.barplot(ax=axes[1], data=df_weekend, x='Heure', y='Comptage horaire', errorbar=None)
    axes[1].set_title("Comptage horaire moyen (week-end)")
    axes[1].set_xlabel("Heure de la journ√©e")
    axes[1].set_ylabel("")  # on peut laisser vide pour all√©ger visuellement
    axes[1].set_ylim(0, 400)

    st.pyplot(fig)

    st.markdown("""
    **Forte augmentation du trafic** aux **heures de pointe** (8h‚Äì9h / 18h‚Äì19h) en semaine.

    **Volume de passages** relativement **r√©gulier** entre **11h et 20h** le **week-end**.
    """)

    st.header("III. Distribution de la variable cible")
    st.subheader('Boxplot global de la variable comptage horaire')

    fig = plt.figure(figsize=(10, 5))
    sns.boxplot(raw_data, x='Comptage horaire')
    st.pyplot(fig)

    st.subheader('Boxplot de la variable comptage horaire en fonction du lieu de comptage')

    agg_data = get_lieux_compteurs_df(raw_data)
    site = st.selectbox("Nom du site de comptage", list(agg_data['Nom du site de comptage'].unique()))
    fig = plt.figure(figsize=(10, 5))
    sns.boxplot(agg_data.loc[agg_data['Nom du site de comptage'] == site], x='Comptage horaire')
    plt.title(site)
    st.pyplot(fig)
    
    st.header("IV. Corr√©lation entre les variables")
    
    st.subheader("Matrice de corr√©lation entre les variables")

    st.image("streamlit_assets/matrice.jpeg", use_container_width=True)

    st.markdown("""
    * Le **comptage horaire** est l√©g√®rement corr√©l√© au **nom du compteur** et √† **l'heure de la journ√©e**.
    * Corr√©lation forte entre les variables **jour_semaine** et **week-end** (variables potentiellement redondantes).
    * Forte corr√©lation entre **"date et heure de comptage"**, **ann√©e** et **mois**.
    """)

   
